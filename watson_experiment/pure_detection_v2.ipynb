{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adopted from \n",
    "# https://github.com/watson-developer-cloud/python-sdk/blob/master/examples/visual_recognition_v4.py\n",
    "\n",
    "import json\n",
    "import os\n",
    "from ibm_watson import VisualRecognitionV4\n",
    "from ibm_watson.visual_recognition_v4 import FileWithMetadata, TrainingDataObject, Location, AnalyzeEnums\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "authenticator = IAMAuthenticator('UNj_AQojzpzeg5q5FvmaMu2a3jathuqDB79_DjpAGJb_')\n",
    "\n",
    "service = VisualRecognitionV4(\n",
    "    '2020-03-20',\n",
    "    authenticator=authenticator)\n",
    "\n",
    "service.set_service_url('https://api.us-south.visual-recognition.watson.cloud.ibm.com/instances/de0d73f8-faaa-4318-9ed6-492a2822bf20')\n",
    "\n",
    "# create a classifier\n",
    "# my_collection = service.create_collection(\n",
    "#     name='obj_detection_test',\n",
    "#     description='testing for python obj detection'\n",
    "# ).get_result()\n",
    "# collection_id = my_collection.get('collection_id')\n",
    "\n",
    "collection_id = \"0105d854-d33a-455a-989f-91ce7048982c\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_img_path = \"/Users/dqin/Documents/FAME/watson_experiment/sample_face_and_result/img_404.jpg\"\n",
    "\n",
    "# Expected output:\n",
    "# 2 FACES (those > 0.5 threshold), with their coordiantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"images\": [\n",
      "    {\n",
      "      \"source\": {\n",
      "        \"type\": \"file\",\n",
      "        \"filename\": \"img_404.jpg\"\n",
      "      },\n",
      "      \"dimensions\": {\n",
      "        \"height\": 316,\n",
      "        \"width\": 450\n",
      "      },\n",
      "      \"objects\": {\n",
      "        \"collections\": [\n",
      "          {\n",
      "            \"collection_id\": \"0105d854-d33a-455a-989f-91ce7048982c\",\n",
      "            \"objects\": [\n",
      "              {\n",
      "                \"object\": \"face\",\n",
      "                \"location\": {\n",
      "                  \"left\": 64,\n",
      "                  \"top\": 72,\n",
      "                  \"width\": 124,\n",
      "                  \"height\": 151\n",
      "                },\n",
      "                \"score\": 0.9937354\n",
      "              },\n",
      "              {\n",
      "                \"object\": \"face\",\n",
      "                \"location\": {\n",
      "                  \"left\": 228,\n",
      "                  \"top\": 30,\n",
      "                  \"width\": 182,\n",
      "                  \"height\": 200\n",
      "                },\n",
      "                \"score\": 0.9686894\n",
      "              }\n",
      "            ]\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# analyze\n",
    "with open(target_img_path, 'rb') as img_f:\n",
    "    analyze_images = service.analyze(\n",
    "        collection_ids=[collection_id],\n",
    "        features=[AnalyzeEnums.Features.OBJECTS.value],\n",
    "        images_file=[\n",
    "            FileWithMetadata(img_f)\n",
    "        ]).get_result()\n",
    "    print(json.dumps(analyze_images, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the sample result to fil\n",
    "with open(\"/Users/dqin/Documents/FAME/watson_experiment/sample_face_and_result/sample_output.json\", \"w\") as f:\n",
    "    json.dump(analyze_images, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.6 64-bit ('ResearchNLP': conda)",
   "language": "python",
   "name": "python36664bitresearchnlpconda9fb3278d4e124d7eada32c7b62ed01c8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
